{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d11b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file\n",
    "\n",
    "def read_file(file_path):\n",
    "    # Function to read the contents of a text file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "txt_file = r\"C:\\Users\\USER\\Desktop\\algoparams.txt\"\n",
    "txt_content = read_file(txt_file)\n",
    "#print(txt_content)\n",
    "json_data = json.loads(txt_content)\n",
    "\n",
    "\n",
    "def print_keys_and_values(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"{' ' * indent}{key}:\")\n",
    "            print_keys_and_values(value, indent + 4)\n",
    "        else:\n",
    "            print(f\"{' ' * indent}{key}: {value}\")\n",
    "\n",
    "# Print keys and values\n",
    "print(\"Keys and values of the JSON data:\")\n",
    "print_keys_and_values(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448beea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working for feature handling\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Load JSON configuration\n",
    "nltk.download('punkt')\n",
    "# Load CSV file\n",
    "data = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\DS_Assignment - internship\\Screening Test - DS\\iris.csv\")\n",
    "feature_handling = json_data['design_state_data']['feature_handling']\n",
    "\n",
    "target_info = json_data[\"design_state_data\"][\"target\"]\n",
    "print(target_info)\n",
    "tokenized_species=[]\n",
    "# Example: Print feature handling details for each feature\n",
    "for feature, details in feature_handling.items():\n",
    "    a=details[\"feature_variable_type\"]\n",
    "    if a !=\"text\":\n",
    "        if details['is_selected']:\n",
    "            if details['feature_details']['missing_values'] == \"Impute\":\n",
    "                print(\"yes\")\n",
    "                if details['feature_details']['impute_with'] == \"Average of values\":\n",
    "                    \n",
    "                # Impute missing values with mean\n",
    "                    imputer = SimpleImputer(strategy='mean')\n",
    "                    data[feature] = imputer.fit_transform(data[[feature]])\n",
    "                    \n",
    "                elif details['feature_details']['impute_with'] == \"custom\":\n",
    "                # Impute missing values with custom value\n",
    "                    imputer = SimpleImputer(strategy='constant', fill_value=details['feature_details']['impute_value'])\n",
    "                    data[feature] = imputer.fit_transform(data[[feature]])\n",
    "    \n",
    "    else:\n",
    "        dummy_species = pd.get_dummies(data['species'])\n",
    "\n",
    "        data = pd.concat([data, dummy_species], axis=1)\n",
    "\n",
    "        data.drop(columns=['species'], inplace=True)\n",
    "        #**We can tokenize for text column but for now i have used One-hotEncoding\n",
    "        #[for species_text in data['species']:\n",
    "            #tokens = word_tokenize(species_text)\n",
    "            tokenized_species.append(tokens)\n",
    "\n",
    "\n",
    "        #data['tokenized_species'] = tokenized_species]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working for Feature Reduction\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(columns=target_info['target'])  # Assuming 'target_column' is the target column\n",
    "y = data[target_info['target']]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a random forest classifier with specified parameters\n",
    "num_of_trees = int(json_data['design_state_data']['feature_reduction']['num_of_trees'])\n",
    "depth_of_trees = int(json_data['design_state_data']['feature_reduction']['depth_of_trees'])\n",
    "num_of_features_to_keep = int(json_data['design_state_data']['feature_reduction']['num_of_features_to_keep'])\n",
    "\n",
    "if(json_data[\"design_state_data\"][\"target\"][\"prediction_type\"] == \"Regression\"):\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=num_of_trees, max_depth=depth_of_trees, random_state=42)\n",
    "\n",
    "    if(json_data['design_state_data']['feature_reduction'][\"feature_reduction_method\"]==\"Tree-based\"):\n",
    "\n",
    "        rf_regressor.fit(X, y)\n",
    "\n",
    "        feature_importances = rf_regressor.feature_importances_\n",
    "\n",
    "        sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "        \n",
    "        selected_features = X.columns[sorted_indices[:num_of_features_to_keep]]\n",
    "\n",
    "        print(\"Selected Features:for Tree-Based are\", selected_features)\n",
    "    elif(json_data['design_state_data']['feature_reduction'][\"feature_reduction_method\"]==\"Principle Component Analysis\"):\n",
    "        pca = PCA(n_components=int(num_of_features_to_keep))\n",
    "\n",
    "        X_pca = pca.fit_transform(X)\n",
    "        rf_regressor.fit(X_pca, y)\n",
    "        print(\"PCA-Selected Features:\")\n",
    "        print(pca.components_)\n",
    "    elif(json_data['design_state_data']['feature_reduction'][\"feature_reduction_method\"]==\"Correlation with target\"):\n",
    "        correlation_with_target = X.corrwith(y).abs().sort_values(ascending=False)\n",
    "        selected_features = correlation_with_target.index[:num_of_features_to_keep]\n",
    "        X_selected = X[selected_features]\n",
    "        pca = PCA(n_components=num_of_features_to_keep)\n",
    "        X_pca = pca.fit_transform(X_selected)\n",
    "        rf_regressor.fit(X_pca, y)\n",
    "\n",
    "        print(\"PCA-Selected Features:\")\n",
    "        print(selected_features)\n",
    "    else:\n",
    "        print(\"No reduction\")\n",
    "else:\n",
    "    print(\"similar approach for classifier using Random Forest Classifier\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98398b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "####WORKING FOR MODELS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "target_info = json_data[\"design_state_data\"][\"target\"]\n",
    "X = data.drop(columns=[json_data[\"design_state_data\"][\"target\"][\"target\"]])  # Features\n",
    "y = data[json_data[\"design_state_data\"][\"target\"][\"target\"]]  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "reg = [\"RandomForestRegressor\",\"GradientBoostedRegressor\", \"LinearRegression\"]  # Add other regression models here\n",
    "\n",
    "csv_file = r\"C:\\Users\\USER\\Downloads\\DS_Assignment - internship\\Screening Test - DS\\iris.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "if target_info[\"prediction_type\"] == \"Regression\":\n",
    "    # Iterate over each regression model\n",
    "    for model_class in reg:\n",
    "        if model_class==\"RandomForestRegressor\":\n",
    "            # Extract hyperparameters for Random Forest Regressor\n",
    "            rf_regressor_params = json_data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"]\n",
    "            n_estimators = rf_regressor_params[\"max_trees\"]\n",
    "            max_depth = rf_regressor_params[\"max_depth\"]\n",
    "            min_samples_leaf_min_value = rf_regressor_params[\"min_samples_per_leaf_min_value\"]\n",
    "            min_samples_leaf_max_value = rf_regressor_params.get(\"min_samples_per_leaf_max_value\")  # Retrieve max_value, or None if not available\n",
    "            min_depth = rf_regressor_params[\"min_depth\"]\n",
    "            max_feature = rf_regressor_params[\"feature_sampling_statergy\"]\n",
    "\n",
    "            \n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_leaf=min_samples_leaf_min_value,\n",
    "                # max_samples_leaf=min_samples_leaf_max_value,\n",
    "                # min_depth=min_depth ,\n",
    "                # max_features=default\n",
    "                # Add other hyperparameters here\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            score = model.score(X_test, y_test)\n",
    "            print(\"Model Score (R^2):\", score)\n",
    "        elif model_class==\"LinearRegression\":\n",
    "           \n",
    "            lr_params = json_data[\"design_state_data\"][\"algorithms\"][\"LinearRegression\"]\n",
    "            parallelism = lr_params[\"parallelism\"]\n",
    "            min_iter = lr_params[\"min_iter\"]\n",
    "            max_iter = lr_params[\"max_iter\"]\n",
    "            min_regparam = lr_params[\"min_regparam\"]\n",
    "            max_regparam = lr_params[\"max_regparam\"]\n",
    "            min_elasticnet = lr_params[\"min_elasticnet\"]\n",
    "            max_elasticnet = lr_params[\"max_elasticnet\"]\n",
    "\n",
    "           \n",
    "            model = LinearRegression(\n",
    "                parallelism=parallelism,\n",
    "                min_iter=min_iter,\n",
    "                max_iter=max_iter,\n",
    "                min_regparam=min_regparam,\n",
    "                max_regparam=max_regparam,\n",
    "                min_elasticnet=min_elasticnet,\n",
    "                max_elasticnet=max_elasticnet\n",
    "                \\\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            score = model.score(X_test, y_test)\n",
    "            print(\"Model Score (R^2):\", score)\n",
    "\n",
    "        elif model_class==\"GradientBoostedRegressor\":\n",
    "            \n",
    "            gb_regressor_params = json_data[\"design_state_data\"][\"algorithms\"][\"GradientBoostedRegressor\"]\n",
    "            n_estimators = gb_regressor_params[\"max_iter\"]\n",
    "            learning_rate = gb_regressor_params[\"learningRate\"]\n",
    "            min_samples_leaf = gb_regressor_params[\"min_subsample\"]\n",
    "            max_samples_leaf = gb_regressor_params[\"max_subsample\"]\n",
    "            min_stepsize = gb_regressor_params[\"min_stepsize\"]\n",
    "            max_stepsize = gb_regressor_params[\"max_stepsize\"]\n",
    "            min_depth = gb_regressor_params[\"min_depth\"]\n",
    "            max_depth = gb_regressor_params[\"max_depth\"]\n",
    "\n",
    "            \n",
    "            model = GradientBoostedRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                max_samples_leaf=max_samples_leaf,\n",
    "                min_stepsize=min_stepsize,\n",
    "                max_stepsize=max_stepsize,\n",
    "                min_depth=min_depth,\n",
    "                max_depth=max_depth\n",
    "                \n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            score = model.score(X_test, y_test)\n",
    "            print(\"Model Score (R^2):\", score)\n",
    "\n",
    "        else:\n",
    "            print(\"Done with regression model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
